{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b1950ae",
   "metadata": {},
   "source": [
    "# Creating datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47e85316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1bd5679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTdatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        \n",
    "        tokenIDs = tokenizer.encode(txt)\n",
    "        \n",
    "        for i in range(0, len(tokenIDs) - max_length, stride):\n",
    "            self.input_ids.append(torch.tensor(tokenIDs[i:i+max_length]))\n",
    "            self.target_ids.append(torch.tensor(tokenIDs[i+1:i+max_length+1]))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return(len(self.input_ids))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input = self.input_ids[index]\n",
    "        label = self.target_ids[index]\n",
    "        return input, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "790f9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_dataloader_V1(txt, tokenizer, batch_size, max_length=256, stride=128,\n",
    "                        shuffle=True, drop_last=True, num_workers=0):\n",
    "    dataset = GPTdatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "                            drop_last=drop_last, num_workers=num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd770bbb",
   "metadata": {},
   "source": [
    "# Multi-Head Attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cce8cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4016579",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_size, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert(d_out%num_heads==0), \"d_out must be a multiple of num_heads\"\n",
    "        self.head_dim = d_out//num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.d_out = d_out\n",
    "        self.Q_layer = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.K_layer = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.V_layer = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_size, context_size), diagonal=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        Q = self.Q_layer(x)\n",
    "        K = self.K_layer(x)\n",
    "        V = self.V_layer(x)\n",
    "\n",
    "        Q = Q.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        K = K.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        V = V.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        \n",
    "        Q.transpose_(1, 2)\n",
    "        K.transpose_(1, 2)\n",
    "        V.transpose_(1, 2)\n",
    "        \n",
    "        attention_scores = Q@K.transpose(-1, -2)\n",
    "        \n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        \n",
    "        attention_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attention_weights = torch.softmax(attention_scores/self.head_dim**0.5, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        context_vec = (attention_weights@V).transpose(1, 2)\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        \n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        \n",
    "        return context_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc82a971",
   "metadata": {},
   "source": [
    "# GPT architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e985c84",
   "metadata": {},
   "source": [
    "**Configuration for the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805d97a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_length\" : 1024,\n",
    "    \"emb_dim\" : 768,\n",
    "    \"n_heads\" : 12,\n",
    "    \"n_layers\" : 12,\n",
    "    \"drop_rate\" : 0.1,\n",
    "    \"qkv_bias\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66094548",
   "metadata": {},
   "source": [
    "**Layer Normalization Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe8749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer_norm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True)\n",
    "        norm_out = (x - mean)/(torch.sqrt(var) + self.eps)\n",
    "        return self.scale*norm_out + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b34389",
   "metadata": {},
   "source": [
    "**GELU activation class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f17c12fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = 0.5*x*(1 + torch.tanh(torch.sqrt(torch.tensor(2/torch.pi))*(x + 0.044715*x**3)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216550e9",
   "metadata": {},
   "source": [
    "**Feed-Forward class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13d5128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4*cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3865d314",
   "metadata": {},
   "source": [
    "**Transformer block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f634f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layer_norm1 = layer_norm(cfg['emb_dim'])\n",
    "        self.Masked_multi_head_attn = MultiHeadAttention(\n",
    "            cfg['emb_dim'], cfg['emb_dim'],\n",
    "            cfg['context_length'], cfg['drop_rate'], cfg['n_heads'], cfg['qkv_bias'])\n",
    "        self.dropout = nn.Dropout(cfg['drop_rate'])\n",
    "        self.layer_norm2 = layer_norm(cfg['emb_dim'])\n",
    "        self.ff = FeedForward(cfg)\n",
    "           \n",
    "    def forward(self, x):\n",
    "        \n",
    "        shortcut = x\n",
    "        \n",
    "        x = self.layer_norm1(x)\n",
    "        x = self.Masked_multi_head_attn(x)\n",
    "        x = self.dropout(x) + shortcut\n",
    "        \n",
    "        shortcut = x\n",
    "        \n",
    "        x = self.layer_norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.dropout(x) + shortcut\n",
    "        \n",
    "        return x\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165d49bd",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20623c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        self.dropout = nn.Dropout(cfg['drop_rate'])\n",
    "        self.transformer_layer = nn.Sequential(*[Transformer(cfg) for _ in range(cfg['n_layers'])])\n",
    "        self.final_norm_layer = layer_norm(cfg['emb_dim'])\n",
    "        self.linear_out_layer = nn.Linear(cfg['emb_dim'], cfg['vocab_size'], bias=False)\n",
    "        \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        token_emb = self.tok_emb(in_idx)\n",
    "        positional_emb = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        embeddings = token_emb + positional_emb\n",
    "        \n",
    "        embeddings = self.dropout(embeddings)\n",
    "        \n",
    "        x = self.transformer_layer(embeddings)\n",
    "        \n",
    "        x = self.final_norm_layer(x)\n",
    "        \n",
    "        logits = self.linear_out_layer(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7378ed",
   "metadata": {},
   "source": [
    "# Simple output tokenID generation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20fd70b",
   "metadata": {},
   "source": [
    "**Text to tokens generation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b014acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input : text and tokenizer\n",
    "# Output : tokens in a single batch (1, num_tokens)\n",
    "def text_to_tokens(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    tokens = torch.tensor(encoded).unsqueeze(0)  # .unsqueeze() converts (n, ) --> (1, n)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9f644",
   "metadata": {},
   "source": [
    "**Input tokens to output tokens generation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f5756ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : idx is the input tokens in batch (num_batches, num_tokens)\n",
    "# output : return num_tokens output tokens concatenated with input tokens\n",
    "# Remember that this returns the output in shape (num_batches, num_tokens) \n",
    "# to convert these tokens into texts we need to arrange all tokens in a\n",
    "# single python list then pass it to the tokenizer.decode() to decode\n",
    "def generated_tokens_simple(model, idx, num_tokens, context_size):\n",
    "    for _ in range(num_tokens):\n",
    "        input = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(input)\n",
    "        logits = logits[:, -1, :]\n",
    "        prob_dist = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(prob_dist, dim=-1, keepdim=True)\n",
    "        idx = torch.cat([idx, idx_next], dim=-1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cdf012",
   "metadata": {},
   "source": [
    "**Tokens to text generation functon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0980fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input : tokens (1, num_tokens)\n",
    "# Output : text\n",
    "def tokens_to_text(tokens, tokenizer):\n",
    "    tokens = tokens.squeeze(0).tolist()  # .squeeze() converts (1, n) --> (n, )\n",
    "    text = tokenizer.decode(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b48abd",
   "metadata": {},
   "source": [
    "# Model Pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2c190",
   "metadata": {},
   "source": [
    "**Cross Entropy Loss calculation funtion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd01a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss calculation for one batch\n",
    "def cal_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    logits = logits.flatten(0, 1)\n",
    "    targets = target_batch.flatten()\n",
    "    loss = nn.functional.cross_entropy(logits, targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b79fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss calculation for whole dataloader\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader)==0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i<num_batches:\n",
    "            loss = cal_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss/num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da5a4e",
   "metadata": {},
   "source": [
    "**Model evaluation function to return Training and Validation losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e84d6886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c715152",
   "metadata": {},
   "source": [
    "**The below function is used for visual evaluation process <br> as it prints sample text outputs during model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dcbc1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_tokens(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        out_tokens = generated_tokens_simple(model=model, idx=encoded,\n",
    "                                          num_tokens=50, context_size=context_size)\n",
    "    decoded_text = tokens_to_text(out_tokens, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac40c0",
   "metadata": {},
   "source": [
    "**Model training function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ec8e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
    "                       num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    \n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = cal_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            \n",
    "            if global_step%eval_freq==0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader,\n",
    "                                                       val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}):\"\n",
    "                      f\"Training loss: {train_loss:.3f},\"\n",
    "                      f\"Validation loss: {val_loss:.3f}\")\n",
    "                \n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "        \n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38724d6e",
   "metadata": {},
   "source": [
    "**Starting to train the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45967d05",
   "metadata": {},
   "source": [
    "**Changing the configuration slightly just by making the context_length=256 from 1024 original**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0417af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    'vocab_size': 50257,\n",
    "    'context_length': 256,\n",
    "    'emb_dim': 768,\n",
    "    'n_heads': 12,\n",
    "    'n_layers': 12,\n",
    "    'drop_rate': 0.1,\n",
    "    'qkv_bias': False\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a86ef2",
   "metadata": {},
   "source": [
    "**Importing \"The-Verdict\" a short story as dataset for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa153b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacfe1cd",
   "metadata": {},
   "source": [
    "**Splitting dataset into training and validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cacd9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitting_frac = 0.9\n",
    "split_idx = int(splitting_frac*len(text_data))\n",
    "train_text = text_data[:split_idx]\n",
    "val_text = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1500dfc4",
   "metadata": {},
   "source": [
    "**Creating training and validation dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "791ca811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ba39bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader = creat_dataloader_V1(train_text,\n",
    "                                    tokenizer,\n",
    "                                    batch_size=2,\n",
    "                                    max_length=GPT_CONFIG_124M['context_length'],\n",
    "                                    stride=GPT_CONFIG_124M['context_length'],\n",
    "                                    shuffle=True,\n",
    "                                    drop_last=True,\n",
    "                                    num_workers=0\n",
    "                                    )\n",
    "val_loader = creat_dataloader_V1(val_text,\n",
    "                                tokenizer,\n",
    "                                batch_size=2,\n",
    "                                max_length=GPT_CONFIG_124M['context_length'],\n",
    "                                stride=GPT_CONFIG_124M['context_length'],\n",
    "                                shuffle=False,\n",
    "                                drop_last=False,\n",
    "                                num_workers=0\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "121d5756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000):Training loss: 9.782,Validation loss: 9.934\n",
      "Ep 1 (Step 000005):Training loss: 8.112,Validation loss: 8.340\n",
      "Every step moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010):Training loss: 6.662,Validation loss: 7.049\n",
      "Ep 2 (Step 000015):Training loss: 5.961,Validation loss: 6.616\n",
      "Every step moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020):Training loss: 5.716,Validation loss: 6.594\n",
      "Ep 3 (Step 000025):Training loss: 5.210,Validation loss: 6.355\n",
      "Every step moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030):Training loss: 4.427,Validation loss: 6.279\n",
      "Ep 4 (Step 000035):Training loss: 4.075,Validation loss: 6.227\n",
      "Every step moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040):Training loss: 3.737,Validation loss: 6.160\n",
      "Every step moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045):Training loss: 2.859,Validation loss: 6.181\n",
      "Ep 6 (Step 000050):Training loss: 2.434,Validation loss: 6.139\n",
      "Every step moves you know,\" was one of the picture. The--I had a little of a and he was no I had the fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055):Training loss: 2.112,Validation loss: 6.133\n",
      "Ep 7 (Step 000060):Training loss: 1.889,Validation loss: 6.232\n",
      "Every step moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065):Training loss: 1.326,Validation loss: 6.238\n",
      "Ep 8 (Step 000070):Training loss: 0.991,Validation loss: 6.244\n",
      "Every step moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075):Training loss: 0.721,Validation loss: 6.293\n",
      "Ep 9 (Step 000080):Training loss: 0.544,Validation loss: 6.391\n",
      "Every step moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisburn's an unusual degree to the display of this false virtuosity. The picture was one of Jack's \"strongest,\" as his\n",
      "Ep 10 (Step 000085):Training loss: 0.394,Validation loss: 6.452\n",
      "Every step moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "start_context = \"Every step moves you\"\n",
    "train_losses, val_losses, track_tokens_seen = train_model_simple(model, train_loader,\n",
    "                                                                 val_loader,\n",
    "                                                                 optimizer, device,\n",
    "                                                                    num_epochs, eval_freq=5,\n",
    "                                                                    eval_iter=5,\n",
    "                                                                    start_context=start_context,\n",
    "                                                                    tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fd731a",
   "metadata": {},
   "source": [
    "**Plotting Training and validation losses over number of epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c654c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d02bb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(epoch_tensor, train_losses, label=\"Training loss\")\n",
    "ax1.plot(epoch_tensor, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "ax1.set_xlabel(\"epochs\")\n",
    "ax1.set_ylabel(\"loss\")\n",
    "ax1.legend()\n",
    "ax2 = ax1.twiny()\n",
    "ax2.plot(track_tokens_seen, train_losses, alpha=0)\n",
    "ax2.set_xlabel(\"Tokens seen\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7f5db4",
   "metadata": {},
   "source": [
    "# Temperature scaling and Top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77c19e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generated_tokens_simple_V2(model, idx, max_new_tokens, context_size,\n",
    "                               temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        input = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(input)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, top_pos = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits<min_val,\n",
    "                                 torch.tensor(float('-inf')).to(logits.device),\n",
    "                                 logits)\n",
    "        if temperature > 0.0:\n",
    "            logits = logits/temperature\n",
    "            prob_dist = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(prob_dist, num_samples=1)\n",
    "        else:\n",
    "            prob_dist = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.argmax(prob_dist, dim=-1, keepdim=True)\n",
    "        if idx_next==eos_id:\n",
    "            break\n",
    "        idx = torch.cat([idx, idx_next], dim=-1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b286f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, input_context, max_new_tokens, context_size,\n",
    "                               temperature=0.0, top_k=None, eos_id=None):\n",
    "    model.eval()\n",
    "    input_tkns = text_to_tokens(input_context, tokenizer)\n",
    "    output_tkns = generated_tokens_simple_V2(model, input_tkns, max_new_tokens, context_size,\n",
    "                               temperature, top_k, eos_id)\n",
    "    output_txt = tokens_to_text(output_tkns, tokenizer)\n",
    "    print(output_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d53535dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every step moves you know,\" was one of the axioms he laid down, so--so of the fact--so of the irony.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"Oh, and told me out--so a deprecating a deprecatingly--\n"
     ]
    }
   ],
   "source": [
    "input_txt = \"Every step moves you\"\n",
    "generate(model=model, input_context=input_txt, max_new_tokens=50, context_size=15, temperature=0.5, top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af647080",
   "metadata": {},
   "source": [
    "# Saving and loading model weights and Optimizer states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0a48cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict' : model.state_dict(),\n",
    "    'optimizer_state_dict' : optimizer.state_dict()\n",
    "            },\n",
    "    'model_and_optimizer.pth'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba5cd8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f785a6",
   "metadata": {},
   "source": [
    "# Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4f21b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "# gpt_download.py is a python file which contains functions to download open source weights from OpenAI\n",
    "\n",
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2edf505",
   "metadata": {},
   "source": [
    "**As same architecture can be used for all GPT2 models we define the config. for all models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1f353ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6a2190b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 256,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df1ab59",
   "metadata": {},
   "source": [
    "**Earlier we set the context_length to 256 from 1024 for the sake of training the model<br>Also OpenAI used bias vectors in the Multihead attention so we are turning qkv_bias to true**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b8a4518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': True}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG.update({'context_length': 1024, 'qkv_bias': True})\n",
    "NEW_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae5ad511",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9628a6",
   "metadata": {},
   "source": [
    "**We will first define a small \"assign\" utility function that checks whether two tensors or arrays (left and right) have the same dimensions or shape and returns the right tensor as trainable PyTorch parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2dda547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape!=right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                         f\"Right: {right.shape}\"\n",
    "                         )\n",
    "    return torch.nn.Parameter(torch.tensor(right, device=left.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc56dcf",
   "metadata": {},
   "source": [
    "### Replacing our weights and biases with OpenAI's weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c998177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_params_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"w\"]), 3, axis=-1)\n",
    "        gpt.transformer_layer[b].Masked_multi_head_attn.Q_layer.weight = assign(\n",
    "            gpt.transformer_layer[b].Masked_multi_head_attn.Q_layer.weight, q_w.T)\n",
    "        gpt.transformer_layer[b].Masked_multi_head_attn.K_layer.weight = assign(\n",
    "            gpt.transformer_layer[b].Masked_multi_head_attn.K_layer.weight, k_w.T)\n",
    "        gpt.transformer_layer[b].Masked_multi_head_attn.V_layer.weight = assign(\n",
    "            gpt.transformer_layer[b].Masked_multi_head_attn.V_layer.weight, v_w.T)\n",
    "        \n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"b\"]), 3, axis=-1)\n",
    "        gpt.transformer_layer[b].Masked_multi_head_attn.Q_layer.bias = assign(\n",
    "            gpt.transformer_layer[b].Masked_multi_head_attn.Q_layer.bias, q_b)\n",
    "        gpt.transformer_layer[b].Masked_multi_head_attn.K_layer.bias = assign(\n",
    "            gpt.transformer_layer[b].Masked_multi_head_attn.K_layer.bias, k_b)\n",
    "        gpt.transformer_layer[b].Masked_multi_head_attn.V_layer.bias = assign(\n",
    "            gpt.transformer_layer[b].Masked_multi_head_attn.V_layer.bias, v_b)\n",
    "        \n",
    "        gpt.transformer_layer[b].Masked_multi_head_attn.out_proj.weight = assign(\n",
    "            gpt.transformer_layer[b].Masked_multi_head_attn.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.transformer_layer[b].Masked_multi_head_attn.out_proj.bias = assign(\n",
    "            gpt.transformer_layer[b].Masked_multi_head_attn.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "        \n",
    "        gpt.transformer_layer[b].ff.layers[0].weight = assign(\n",
    "            gpt.transformer_layer[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.transformer_layer[b].ff.layers[0].bias = assign(\n",
    "            gpt.transformer_layer[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.transformer_layer[b].ff.layers[2].weight = assign(\n",
    "            gpt.transformer_layer[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.transformer_layer[b].ff.layers[2].bias = assign(\n",
    "            gpt.transformer_layer[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        \n",
    "        gpt.transformer_layer[b].layer_norm1.scale = assign(\n",
    "            gpt.transformer_layer[b].layer_norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.transformer_layer[b].layer_norm1.shift = assign(\n",
    "            gpt.transformer_layer[b].layer_norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.transformer_layer[b].layer_norm2.scale = assign(\n",
    "            gpt.transformer_layer[b].layer_norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.transformer_layer[b].layer_norm2.shift = assign(\n",
    "            gpt.transformer_layer[b].layer_norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "        \n",
    "    gpt.final_norm_layer.scale = assign(gpt.final_norm_layer.scale, params[\"g\"])\n",
    "    gpt.final_norm_layer.shift = assign(gpt.final_norm_layer.shift, params[\"b\"])\n",
    "    gpt.linear_out_layer.weight = assign(gpt.linear_out_layer.weight, params[\"wte\"])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a8115de",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_params_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1c480c",
   "metadata": {},
   "source": [
    "### Giving some input to the model and if model produces some coherent text then everything is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82b36171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education is the key to building the future of the next generationour kids and this world,\" Doreen Doss told the Washington Examiner recently!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(353)\n",
    "input_context = \"Education is the key to\"\n",
    "output = generate(model=gpt, input_context=input_context,\n",
    "                  max_new_tokens=25, context_size=1024,\n",
    "                  temperature=1.5, top_k=50)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llmFS)",
   "language": "python",
   "name": "llmfsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
